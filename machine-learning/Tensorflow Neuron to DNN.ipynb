{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F95Jz5-BeuM5"
   },
   "source": [
    "# Quick Inference Model using a single Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dupUWmRgopCC"
   },
   "source": [
    "Lets delete any saved model if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tHmFpHBXer83",
    "outputId": "3c0bd440-eb68-44e1-9599-96ec1f0e5db1"
   },
   "outputs": [],
   "source": [
    "!rm mymodel.hd5\n",
    "!mkdir -p temp/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if needed\n",
    "#!pip install -U tensorflow matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txB7Grmcooml"
   },
   "source": [
    "Load the libraries and if a model exists load that, if not we'll load a saved model. It is a single perceptron using a linear activation (default) and a Stochastic Gradient Descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vd6T2PYdQTpM",
    "outputId": "618388b4-fd25-4cc6-f15a-2b5b3faf5c9d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#NN def image\n",
    "#import pydot\n",
    "from IPython.display import Image\n",
    "import time\n",
    "\n",
    "#Careful with the below\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "try:\n",
    "  model=tf.keras.models.load_model('./mymodel.hd5')\n",
    "  print(\"model loaded\")\n",
    "except:\n",
    "  print(\"Creating new model\")\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(1, input_dim=1))\n",
    "  model.compile(loss='mean_squared_error',optimizer='sgd')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7nkLEGlY-jW"
   },
   "outputs": [],
   "source": [
    "def predict(model=None,xs=None,ys=None,predict=None,line=True):\n",
    "    \"\"\"\n",
    "    Given a model and data build a prediction and graph it's accuracy\n",
    "    \"\"\"\n",
    "    to_predict = predict\n",
    "    predicted = model.predict(to_predict)[:,0]\n",
    "    x_show=np.concatenate((xs, to_predict), axis=0)\n",
    "    y_show=np.concatenate((ys, predicted),axis=0)\n",
    "    c_show=np.concatenate((np.repeat('blue',len(xs+1)),np.repeat('red',len(to_predict+1))))\n",
    "    data=pd.DataFrame({'x':x_show,'y':y_show,'colors':c_show})\n",
    "\n",
    "    data.plot.scatter(x='x',y='y',c=c_show)\n",
    "    #z = np.polyfit(data['x'], data['y'], 1)\n",
    "    if line:\n",
    "      z1 = np.polyfit(to_predict, predicted, 1)\n",
    "      p1 = np.poly1d(z1)\n",
    "      z2 = np.polyfit(xs, ys, 1)\n",
    "      p2 = np.poly1d(z2)\n",
    "      plt.plot(x_show,p2(x_show),\"b-\")\n",
    "      plt.plot(data['x'],p1(data['x']),\"r--\")\n",
    "\n",
    "      # the line equation:\n",
    "      print(\"y=%.6fx+(%.6f)\"%(z1[0],z1[1]))\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_model(model,image_name=None):\n",
    "    \"\"\"\n",
    "    Given a NN model, draw the rough diagram of the neural network\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    model_config=model.get_config()\n",
    "    layer=[]\n",
    "    #print('Model has {} layers'.format(len(model_config['layers'])))\n",
    "    layer.append('layer 0_0')\n",
    "    for i in range(len(model_config['layers'])):\n",
    "        try: \n",
    "            inputs=model_config['layers'][i-1]['config']['units']\n",
    "        except:\n",
    "            inputs=1\n",
    "        new_layer=list(range(inputs))\n",
    "        for j in range(inputs):\n",
    "            try:\n",
    "                for k in range(model_config['layers'][i]['config']['units']):\n",
    "                    new_layer.append('layer {}_{}'.format(i+1,k))\n",
    "                    G.add_edge('layer {}_{}'.format(i,j),'layer {}_{}'.format(i+1,k))\n",
    "                    #print('layer {}_{} to layer {}_{}'.format(i,j,i+1,k))\n",
    "            except:\n",
    "                continue\n",
    "        layer.append(new_layer)\n",
    "    A = nx.nx_agraph.to_agraph(G)\n",
    "    for i in range(len(layer)):\n",
    "        A.add_subgraph(layer[i],rank='same')                       \n",
    "    A.draw(image_name,prog='dot')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGAmT9zTo2tl"
   },
   "source": [
    "Here is the data we are going to load. Its a straight linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qh6rTujvoc24"
   },
   "outputs": [],
   "source": [
    "size=7\n",
    "xs = np.linspace(-1,size-1,num=size)\n",
    "ys = np.add(2*xs-1,0.3*(2*np.random.normal(size=size)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "3l3eqUPKpOeC",
    "outputId": "0958b9b2-2319-480e-ce37-16620d33c3c8"
   },
   "outputs": [],
   "source": [
    "plt.plot(xs,ys,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IQYUA6Eio0lU",
    "outputId": "86da5b50-1669-4c5a-9de4-173f13e88045"
   },
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=1,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rnLAiGfofle"
   },
   "source": [
    "## Prediction\n",
    "Lets test the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L2cSrUKGoesk",
    "outputId": "86ddf018-0131-4356-9d10-b745e2ea56be"
   },
   "outputs": [],
   "source": [
    "to_predict = np.array([10,11,12,13])\n",
    "predicted = model.predict(to_predict)[:,0]\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='temp/images/model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "YmDHxwWTZ0Kw",
    "outputId": "bf15a1c4-1c22-4cea-cf86-365847e9f2a9"
   },
   "outputs": [],
   "source": [
    "predict(model=model,xs=xs,ys=ys,predict=np.array([10,11,12,13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQ-cGOz7uwf3"
   },
   "source": [
    "Not great, but not bad for 5 tries. Lets do another 10 passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "oyJxVETqu1q-",
    "outputId": "5814c9af-3e09-4f09-8254-5111a5fdafac"
   },
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=10,verbose=0)\n",
    "\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array([10,11,12,13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "frOByor4xJ7Y",
    "outputId": "5b149617-133f-4c47-b330-60f03e9c4554"
   },
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=10,verbose=0)\n",
    "\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array([10,11,12,13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "qOaF5N0LxK9y",
    "outputId": "2b0e5b18-44f3-41f5-dbb9-b1d4a0c0f075"
   },
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=10,verbose=0)\n",
    "\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array([10,11,12,13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "Cm_MouyQxLUR",
    "outputId": "6c24d9a4-59a2-416f-90d3-c88f6d1dd160"
   },
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=10,verbose=0)\n",
    "\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array([10,11,12,13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WZos46vxQ_P"
   },
   "source": [
    "## full tilt, 10000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "Woto4RBaxLmr",
    "outputId": "c99211c4-6a74-4a33-9527-817ad88a2dea"
   },
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=10000,verbose=0)\n",
    "\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array([10,11,12,13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qk-cGhdlaNmb"
   },
   "source": [
    "## Save the model\n",
    "\n",
    "Now we can save the model for use later. Yay!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Ma4OCMQoZ3J",
    "outputId": "da43cf2f-db8b-485f-c6bc-23d0ced8d30e"
   },
   "outputs": [],
   "source": [
    "#model.save('mymodel.hd5')\n",
    "#print(\"./model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complicated Data\n",
    "\n",
    "Lets do a test with parabolic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HheCxP52XZPD"
   },
   "outputs": [],
   "source": [
    "size=7\n",
    "xs = np.linspace(-1,size-1,num=size)\n",
    "ys = np.add(2*xs*xs-10*xs-1,0.3*(2*np.random.normal(size=size)-1))\n",
    "plt.plot(xs,ys,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xs,ys,epochs=100,verbose=0)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array([4.1,4.2,4.3,4.4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines don't work, so let's make the model detect two parts. so instead of 1 neuron in the layer let's have 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(2, input_dim=1))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=100,verbose=0)\n",
    "time_end = time.time()\n",
    "print(time_end-time_start)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='temp/images/model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Line plus a line is a line, we need something non-linear. Lets add an activation function. In this scenario we'll use the ReLU activation, anything +ve is linear, anything -ve is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(2, input_dim=1,activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='temp/images/model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but lets see if we can pick up more complex shapes by making it 5 input layers (5 line segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')\n",
    "\n",
    "epochs=1000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will 10 neurons make it better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, input_dim=1,activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get better data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints=50\n",
    "xs = np.linspace(-1,size-1,num=datapoints)\n",
    "ys = np.add(2*xs*xs-10*xs-1,0.3*(2*np.random.normal(size=datapoints)-1))\n",
    "plt.plot(xs,ys,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add a new layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Change to Sigmoid and see if we can get a smoother curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')\n",
    "\n",
    "#draw_model(model,'temp/images/image_5.png')\n",
    "#Image(filename='temp/images/image_5.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets change the initialization functions (random normal limited (he_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.sigmoid,kernel_initializer='he_normal',\n",
    "                bias_initializer='zeros'))\n",
    "model.add(tf.keras.layers.Dense(5, input_dim=1,activation=tf.keras.activations.sigmoid,kernel_initializer='he_normal',\n",
    "                bias_initializer='zeros'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "time_start = time.time()\n",
    "model.fit(xs,ys,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print((time_end-time_start)/epochs)\n",
    "predict(model=model,xs=xs,ys=ys,predict=np.array(np.linspace(-1,size-1,num=100)),line=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "datapoints=100\n",
    "xs = np.linspace(-1,1,num=datapoints)\n",
    "ys = np.linspace(-1,1,num=datapoints)\n",
    "\n",
    "def f(x):\n",
    "    return (x[0]**2)+(x[1]**3)+0.05*np.reshape((2*np.random.normal(size=datapoints*datapoints)-1),(datapoints,datapoints))\n",
    "\n",
    "fig = plt.figure()\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "Z = f([X, Y])\n",
    "\n",
    "#ax = plt.axes(projection='3d')\n",
    "#ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "#ax.view_init(30,45)\n",
    "#plt.draw()\n",
    "plt.contourf(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(X,Y,Z,title=None,xlim=None,ylim=None,zlim=None):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    ax.view_init(30,30)\n",
    "    #plt.draw()\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    if zlim:\n",
    "        ax.set_zlim(zlim[0], zlim[1])\n",
    "    plt.scatter(X,Y,Z)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(X,Y,(Z),title='Target',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(5,input_dim=2,activation=tf.keras.activations.sigmoid,kernel_initializer='he_normal',\n",
    "                bias_initializer='zeros'))\n",
    "model.add(tf.keras.layers.Dense(5,activation=tf.keras.activations.relu,kernel_initializer='he_normal',\n",
    "                bias_initializer='zeros'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\n",
    "    'x':list(X.reshape(-1)),\n",
    "    'y':list(Y.reshape(-1)),\n",
    "#    'z':f([X.reshape(-1),Y.reshape(-1)])})\n",
    "    'z':Z.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df[['x','y']].values\n",
    "labels=df[['z']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "time_start = time.time()\n",
    "history = model.fit(features,labels,batch_size=32,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='temp/images/model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict([1,1])[:,0].reshape(1,-1)\n",
    "Zp=model.predict(features)[:,0].reshape(100,100)\n",
    "Zp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(features)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(X,Y,(Z),title='Target',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])\n",
    "plot_df(X,Y,(Zp),title='Predicted',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])\n",
    "plot_df(X,Y,(Z-Zp),title='Error',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(25,input_dim=2,activation=tf.keras.activations.sigmoid,kernel_initializer='he_normal',\n",
    "                bias_initializer='zeros'))\n",
    "model.add(tf.keras.layers.Dense(25,activation=tf.keras.activations.sigmoid,kernel_initializer='he_normal',\n",
    "                bias_initializer='zeros'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "time_start = time.time()\n",
    "history = model.fit(features,labels,batch_size=32,epochs=epochs,verbose=0)\n",
    "time_end = time.time()\n",
    "print(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='temp/images/model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "Zp=model.predict(features)[:,0].reshape(100,100)\n",
    "time_end = time.time()\n",
    "print(time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(X,Y,(Z),title='Target',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])\n",
    "plot_df(X,Y,(Zp),title='Predicted',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])\n",
    "plot_df(X,Y,(Z-Zp),title='Error',xlim=[-1,1],ylim=[-1,1],zlim=[-1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow_inference1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
